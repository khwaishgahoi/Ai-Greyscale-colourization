{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting dataset and loading it in the environment"
      ],
      "metadata": {
        "id": "LLLT5Kw82YvZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRIlk6Ox2SLG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths to tar.gz files in Google Drive\n",
        "mountain_tar_path = '/content/drive/MyDrive/seminar_proj_dataset/mountain.tar.gz'\n",
        "forest_tar_path = '/content/drive/MyDrive/seminar_proj_dataset/forest_path.tar.gz'\n",
        "\n",
        "# Extract tar.gz files\n",
        "mountain_extract_dir = '/content/mountain'\n",
        "forest_extract_dir = '/content/forest_path'\n",
        "\n",
        "for tar_path, extract_dir in [(mountain_tar_path, mountain_extract_dir), (forest_tar_path, forest_extract_dir)]:\n",
        "    if not os.path.exists(extract_dir):  # Avoid re-extracting\n",
        "        with tarfile.open(tar_path, 'r:gz') as tar:\n",
        "            tar.extractall(path=extract_dir)\n",
        "\n",
        "# Assuming tar files contain folders 'mountain' and 'forest_path' respectively\n",
        "mountain_base_dir = os.path.join(mountain_extract_dir, 'mountain')\n",
        "forest_base_dir = os.path.join(forest_extract_dir, 'forest_path')\n",
        "\n",
        "# Collect image paths from both folders\n",
        "mountain_image_paths = glob.glob(os.path.join(mountain_base_dir, '**', '*.jpg'), recursive=True)\n",
        "forest_image_paths = glob.glob(os.path.join(forest_base_dir, '**', '*.jpg'), recursive=True)\n",
        "\n",
        "# Combine and shuffle all image paths\n",
        "all_image_paths = mountain_image_paths + forest_image_paths\n",
        "print(f\"Total mountain images: {len(mountain_image_paths)}\")\n",
        "print(f\"Total forest images: {len(forest_image_paths)}\")\n",
        "print(f\"Total combined images: {len(all_image_paths)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and preprocessing the data for input for training and visualizaing it as well"
      ],
      "metadata": {
        "id": "A5PMPs_e2ulg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load all mountain and forest images (combined logic from earlier loader)\n",
        "mountain_base_dir = '/content/dataset_combined/mountain'\n",
        "forest_base_dir = '/content/dataset_combined/forest_path'\n",
        "\n",
        "mountain_image_paths = glob.glob(os.path.join(mountain_base_dir, '**', '*.jpg'), recursive=True)\n",
        "forest_image_paths = glob.glob(os.path.join(forest_base_dir, '**', '*.jpg'), recursive=True)\n",
        "\n",
        "# Combine both sets\n",
        "image_paths = sorted(mountain_image_paths + forest_image_paths)\n",
        "print(f\"Total images found: {len(image_paths)}\")\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    img_bgr = cv2.imread(image_path)\n",
        "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "    img_rgb = cv2.resize(img_rgb, (128, 128))\n",
        "\n",
        "    img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2Lab)\n",
        "\n",
        "    L_channel = img_lab[:, :, 0:1].astype(np.float32) / 255.0\n",
        "    ab_channels = (img_lab[:, :, 1:].astype(np.float32) - 128.0) / 127.0\n",
        "\n",
        "    return L_channel, ab_channels\n",
        "\n",
        "def view_preprocessed_image(image_path):\n",
        "    L_channel, ab_channels = preprocess_image(image_path)\n",
        "\n",
        "    # Denormalize\n",
        "    L_denorm = L_channel * 100.0\n",
        "    ab_denorm = ab_channels * 128.0\n",
        "\n",
        "    # Ensure ab_channels are in the proper range [-128, 128]\n",
        "    ab_denorm = np.clip(ab_denorm, -128, 128)\n",
        "\n",
        "    # Concatenate the L channel and ab channels to form the Lab image\n",
        "    lab_image = np.concatenate((L_denorm, ab_denorm), axis=-1)\n",
        "\n",
        "    # Convert Lab image to uint8 (range 0-255)\n",
        "    lab_image_uint8 = np.clip(lab_image, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Convert the Lab image to RGB\n",
        "    rgb_image = cv2.cvtColor(lab_image, cv2.COLOR_Lab2RGB)\n",
        "\n",
        "    print(\"L_channel min/max:\", L_channel.min(), L_channel.max())\n",
        "    print(\"ab_channel min/max:\", ab_channels.min(), ab_channels.max())\n",
        "    print(\"L_denorm min/max:\", L_denorm.min(), L_denorm.max())\n",
        "    print(\"ab_denorm min/max:\", ab_denorm.min(), ab_denorm.max())\n",
        "\n",
        "    original_img = cv2.imread(image_path)\n",
        "    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
        "    original_img = cv2.resize(original_img, (128, 128))\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(original_img)\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(rgb_image)\n",
        "    plt.title('Preprocessed Reconstructed Image')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.imshow(L_channel.squeeze(), cmap='gray')\n",
        "    plt.title('Preprocessed L Channel (Grayscale)')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def prepare_data(image_paths):\n",
        "    # 90% train, 5% val, 5% test\n",
        "    train_val_paths, test_paths = train_test_split(image_paths, test_size=0.05, random_state=42)\n",
        "    train_paths, val_paths = train_test_split(train_val_paths, test_size=0.05263, random_state=42)  # ~5% of total\n",
        "\n",
        "    print(f\"Train: {len(train_paths)}, Val: {len(val_paths)}, Test: {len(test_paths)}\")\n",
        "\n",
        "    def batch_preprocess(paths):\n",
        "        L_all, ab_all = [], []\n",
        "        for path in paths:\n",
        "            L, ab = preprocess_image(path)\n",
        "            L_all.append(L)\n",
        "            ab_all.append(ab)\n",
        "        return np.array(L_all), np.array(ab_all)\n",
        "\n",
        "    L_train, ab_train = batch_preprocess(train_paths)\n",
        "    L_val, ab_val = batch_preprocess(val_paths)\n",
        "    L_test, ab_test = batch_preprocess(test_paths)\n",
        "\n",
        "    print(\"Train L shape:\", L_train.shape, \"| ab shape:\", ab_train.shape)\n",
        "    print(\"Val   L shape:\", L_val.shape, \"| ab shape:\", ab_val.shape)\n",
        "    print(\"Test  L shape:\", L_test.shape, \"| ab shape:\", ab_test.shape)\n",
        "\n",
        "    return (L_train, ab_train), (L_val, ab_val), (L_test, ab_test), train_paths, val_paths, test_paths\n",
        "\n",
        "# ðŸ‘‡ Prepare and visualize\n",
        "(L_train, ab_train), (L_val, ab_val), (L_test, ab_test), train_paths, val_paths, test_paths = prepare_data(image_paths)\n",
        "\n",
        "view_preprocessed_image(train_paths[700])\n"
      ],
      "metadata": {
        "id": "r0k-TOr72vOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building model architecture"
      ],
      "metadata": {
        "id": "6AldZxdf3Hvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "def build_unet_model(input_shape=(128, 128, 1)):\n",
        "    \"\"\"\n",
        "    Build a lightweight U-Net model with dropout for image colorization.\n",
        "    Args:\n",
        "        input_shape: Shape of input L channel (default: [128, 128, 1]).\n",
        "    Returns:\n",
        "        Keras Model predicting ab channels [128, 128, 2].\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    # Block 1\n",
        "    conv1 = layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
        "    conv1 = layers.Conv2D(32, 3, padding='same')(conv1)\n",
        "    conv1 = layers.BatchNormalization()(conv1)\n",
        "    conv1 = layers.Activation('relu')(conv1)\n",
        "    pool1 = layers.AveragePooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    # Block 2\n",
        "    conv2 = layers.Conv2D(64, 3, padding='same', activation='relu')(pool1)\n",
        "    conv2 = layers.Conv2D(64, 3, padding='same')(conv2)\n",
        "    conv2 = layers.BatchNormalization()(conv2)\n",
        "    conv2 = layers.Activation('relu')(conv2)\n",
        "    pool2 = layers.AveragePooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    # Block 3\n",
        "    conv3 = layers.Conv2D(128, 3, padding='same', activation='relu')(pool2)\n",
        "    conv3 = layers.Conv2D(128, 3, padding='same')(conv3)\n",
        "    conv3 = layers.BatchNormalization()(conv3)\n",
        "    conv3 = layers.Activation('relu')(conv3)\n",
        "    pool3 = layers.AveragePooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    # Block 4\n",
        "    conv4 = layers.Conv2D(256, 3, padding='same', activation='relu')(pool3)\n",
        "    conv4 = layers.Conv2D(256, 3, padding='same')(conv4)\n",
        "    conv4 = layers.BatchNormalization()(conv4)\n",
        "    conv4 = layers.Activation('relu')(conv4)\n",
        "    pool4 = layers.AveragePooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv5 = layers.Conv2D(256, 3, padding='same', activation='relu')(pool4)\n",
        "    conv5 = layers.Conv2D(256, 3, padding='same')(conv5)\n",
        "    conv5 = layers.BatchNormalization()(conv5)\n",
        "    conv5 = layers.Activation('relu')(conv5)\n",
        "    conv5 = layers.Dropout(0.3)(conv5)\n",
        "\n",
        "    # Decoder\n",
        "    # Block 4\n",
        "    up6 = layers.UpSampling2D(size=(2, 2))(conv5)\n",
        "    up6 = layers.Concatenate()([up6, conv4])\n",
        "    conv6 = layers.Conv2D(128, 3, padding='same', activation='relu')(up6)\n",
        "    conv6 = layers.Conv2D(128, 3, padding='same')(conv6)\n",
        "    conv6 = layers.BatchNormalization()(conv6)\n",
        "    conv6 = layers.Activation('relu')(conv6)\n",
        "    conv6 = layers.Dropout(0.3)(conv6)\n",
        "\n",
        "    # Block 3\n",
        "    up7 = layers.UpSampling2D(size=(2, 2))(conv6)\n",
        "    up7 = layers.Concatenate()([up7, conv3])\n",
        "    conv7 = layers.Conv2D(64, 3, padding='same', activation='relu')(up7)\n",
        "    conv7 = layers.Conv2D(64, 3, padding='same')(conv7)\n",
        "    conv7 = layers.BatchNormalization()(conv7)\n",
        "    conv7 = layers.Activation('relu')(conv7)\n",
        "    conv7 = layers.Dropout(0.3)(conv7)\n",
        "\n",
        "    # Block 2\n",
        "    up8 = layers.UpSampling2D(size=(2, 2))(conv7)\n",
        "    up8 = layers.Concatenate()([up8, conv2])\n",
        "    conv8 = layers.Conv2D(32, 3, padding='same', activation='relu')(up8)\n",
        "    conv8 = layers.Conv2D(32, 3, padding='same')(conv8)\n",
        "    conv8 = layers.BatchNormalization()(conv8)\n",
        "    conv8 = layers.Activation('relu')(conv8)\n",
        "    conv8 = layers.Dropout(0.3)(conv8)\n",
        "\n",
        "    # Block 1\n",
        "    up9 = layers.UpSampling2D(size=(2, 2))(conv8)\n",
        "    up9 = layers.Concatenate()([up9, conv1])\n",
        "    conv9 = layers.Conv2D(32, 3, padding='same', activation='relu')(up9)\n",
        "    conv9 = layers.Conv2D(32, 3, padding='same')(conv9)\n",
        "    conv9 = layers.BatchNormalization()(conv9)\n",
        "    conv9 = layers.Activation('relu')(conv9)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Conv2D(2, 3, padding='same', activation='tanh')(conv9)\n",
        "\n",
        "    return Model(inputs, outputs, name='Lightweight_U-Net_Colorization')\n",
        "\n",
        "# Build and summarize the model\n",
        "model = build_unet_model(input_shape=(128, 128, 1))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "_NisqPKV3ITa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining custom metrics (SSIM & PSNR) and training the model\n"
      ],
      "metadata": {
        "id": "rsKClolI3Tqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, callbacks\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Define custom metrics (SSIM and PSNR)\n",
        "def ssim_metric(y_true, y_pred):\n",
        "    y_true_scaled = (y_true + 1) / 2\n",
        "    y_pred_scaled = (y_pred + 1) / 2\n",
        "    return tf.reduce_mean(tf.image.ssim(y_true_scaled, y_pred_scaled, max_val=1.0))\n",
        "\n",
        "def psnr_metric(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.image.psnr(y_true, y_pred, max_val=2.0))\n",
        "\n",
        "# Compile the model (assumes 'model' is already defined)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='mse',\n",
        "    metrics=['mse', ssim_metric, psnr_metric]\n",
        ")\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=8,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = callbacks.ModelCheckpoint(\n",
        "    filepath='/content/drive/MyDrive/mountains_forest_u_net_best.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model using in-memory NumPy arrays\n",
        "history = model.fit(\n",
        "    x=L_train,\n",
        "    y=ab_train,\n",
        "    validation_data=(L_val, ab_val),\n",
        "    batch_size=64,\n",
        "    epochs=30,\n",
        "    callbacks=[early_stopping, checkpoint],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "_4-uz0Wm3SNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing the results and visualizing the output produced\n"
      ],
      "metadata": {
        "id": "BHk49WHw3r1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Convert normalized Lab to RGB\n",
        "def lab_to_rgb(L, ab):\n",
        "    L = L * 100.0\n",
        "    ab = ab * 128.0\n",
        "    lab = np.concatenate((L, ab), axis=-1).astype(np.float32)\n",
        "    # lab = np.clip(lab, 0, 255).astype(np.uint8)\n",
        "    rgb = cv2.cvtColor(lab, cv2.COLOR_Lab2RGB)\n",
        "    return np.clip(rgb, 0, 1)  # Scale to [0,1] for visualization\n",
        "\n",
        "# Pick 10 samples from test set\n",
        "num_samples = 10\n",
        "L_sample = L_test[num_samples:]\n",
        "ab_true_sample = ab_test[num_samples:]\n",
        "\n",
        "# Predict ab channels\n",
        "ab_pred_sample = model.predict(L_sample, verbose=1)\n",
        "\n",
        "# Convert Lab to RGB for display\n",
        "rgb_original = [lab_to_rgb(L, ab) for L, ab in zip(L_sample, ab_true_sample)]\n",
        "rgb_colorized = [lab_to_rgb(L, ab) for L, ab in zip(L_sample, ab_pred_sample)]\n",
        "grayscale = [L.squeeze() for L in L_sample]\n",
        "\n",
        "# Calculate metrics\n",
        "mse_scores = [np.mean((true - pred) ** 2) for true, pred in zip(ab_true_sample, ab_pred_sample)]\n",
        "ssim_scores = [tf.image.ssim((true + 1) / 2, (pred + 1) / 2, max_val=1.0).numpy() for true, pred in zip(ab_true_sample, ab_pred_sample)]\n",
        "psnr_scores = [tf.image.psnr(true, pred, max_val=2.0).numpy() for true, pred in zip(ab_true_sample, ab_pred_sample)]\n",
        "\n",
        "print(f\"\\nAverage MSE: {np.mean(mse_scores):.4f}\")\n",
        "print(f\"Average SSIM: {np.mean(ssim_scores):.4f}\")\n",
        "print(f\"Average PSNR: {np.mean(psnr_scores):.2f} dB\")\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(15, 30))\n",
        "for i in range(num_samples):\n",
        "    plt.subplot(num_samples, 3, i * 3 + 1)\n",
        "    plt.imshow(rgb_original[i])\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(num_samples, 3, i * 3 + 2)\n",
        "    plt.imshow(grayscale[i], cmap='gray')\n",
        "    plt.title('Grayscale')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(num_samples, 3, i * 3 + 3)\n",
        "    plt.imshow(rgb_colorized[i])\n",
        "    plt.title('Colorized')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7AjL8oJK32Lm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}